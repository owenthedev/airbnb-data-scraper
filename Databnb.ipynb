{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Databnb.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FsHSqnxyB2ML",
        "_L6LSUtPUPvt",
        "vHLZccgNjJLa"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# *AirBNB Data Scraper*"
      ],
      "metadata": {
        "id": "TGavfT8l321q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import packages and libraries**"
      ],
      "metadata": {
        "id": "btUKEtDUUZdZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT6cKA6rMYK7"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insert url to scrape\n",
        "Note:Airbnb url does not need headers"
      ],
      "metadata": {
        "id": "H6SPx-bSUmhf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Getting the number of pages to scrape**"
      ],
      "metadata": {
        "id": "m6jcllIeo5qT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EdCmyLoSnl1"
      },
      "source": [
        "\n",
        "#hheaders = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'}\n",
        "page = 0\n",
        "#The url is broken up to be easily manipulated\n",
        "urlcore=\"https://www.airbnb.co.za/s/Johannesburg--Gauteng--South-Africa/homes?pagination_search=true&items_offset=\"\n",
        "urldates=\"&section_offset=2&checkin=2022-06-24&checkout=2022-06-26\"\n",
        "u=urlcore+str(page*20)+urldates\n",
        "\n",
        "#Fetch the page and its contents\n",
        "request=requests.get(u)\n",
        "content=(request.content)\n",
        "print(content,'\\n',u)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find max number of pages to scrape\n",
        "soup=BeautifulSoup(content,'lxml')\n",
        "pages=[]\n",
        "for pr in soup.find_all(class_=\"_833p2h\"):\n",
        "  pages.append(pr.text)\n",
        "l=len(pages)-1\n",
        "maxp=pages[l]\n",
        "maxp=int(maxp)\n",
        "print(maxp)\n"
      ],
      "metadata": {
        "id": "KPawwne6NApz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating lists for Listing's name, Listing's price, Listing's rating**"
      ],
      "metadata": {
        "id": "RsqJ-bbipDnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "namesa=[]\n",
        "pricesa=[]\n",
        "ratingsa=[]\n",
        "  \n",
        "page = 0\n",
        "numpage=maxp\n",
        "while page<numpage:\n",
        "  urlx=u\n",
        "  request=requests.get(urlx)\n",
        "  content=request.content\n",
        "  soup=BeautifulSoup(content,'lxml')\n",
        "  #classes are found using inspect in the browser\n",
        "  for pr in soup.find_all(class_=\"_tyxjp1\"):\n",
        "    pricesa.append(pr.text)\n",
        "  \n",
        "  for ns in soup.find_all(class_=\"t1jojoys dir dir-ltr\"):\n",
        "    namesa.append(ns.text)\n",
        "  \n",
        "  for ns in soup.find_all(class_=\"ru0q88m dir dir-ltr\"):\n",
        "    ratingsa.append(ns.text)\n",
        "  page = page+1\n",
        "\n",
        "#check if list lengths are the same verify scraping accuracy\n",
        "print(len(pricesa))\n",
        "print(len(namesa))\n",
        "print(len(ratingsa))\n",
        "if(len(pricesa)==len(namesa) & len(ratingsa)==len(pricesa)):\n",
        "  print(\"All good\")\n",
        "else:\n",
        "    print(\"We have a problem\")\n",
        "  "
      ],
      "metadata": {
        "id": "WC4xye8lGvFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print out the lists\n",
        "print(pricesa,\"\\n\",namesa,\"\\n\",ratingsa)"
      ],
      "metadata": {
        "id": "3OZXu_Wma27u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert string of prices and ratings into floats\n",
        "pricesaNum=[]\n",
        "ratingsaNum=[]\n",
        "count=0\n",
        "while count<(len(pricesa)):\n",
        "      #remove dollar sign\n",
        "      ord=pricesa[count][1:].replace('ZAR','')\n",
        "      ord=ord.replace(',','')\n",
        "      #ord=ord.replace(' ZA','')\n",
        "      #remove new ratings, give them aa rating of 4.2\n",
        "      ord2=ratingsa[count].replace('New','4.2')\n",
        "      ord2=ord2.replace('(','')\n",
        "      ord2=ord2.replace(')','')\n",
        "      ord2=ord2.replace(' ','')\n",
        "      pricesaNum.append(float(ord))\n",
        "      ratingsaNum.append(float(ord2))\n",
        "      count=count+1\n",
        "print(pricesaNum,\"\\n\",ratingsaNum)"
      ],
      "metadata": {
        "id": "y6g1EZGG0C80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create a dataframe and csv file**"
      ],
      "metadata": {
        "id": "zEXEh16gqftR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creates an empty dataframe called staysdf\n",
        "staysdf=pd.DataFrame()\n",
        "\n",
        "#Loads lists into ccolumns in staysdf\n",
        "staysdf['Price']=pricesaNum\n",
        "staysdf['Name']=namesa\n",
        "staysdf['Ratings']=ratingsaNum\n",
        "\n",
        "# Create a csv file\n",
        "staysdf.to_csv('airbnb.csv',index=False)\n",
        "staysdf\n"
      ],
      "metadata": {
        "id": "25oqCgkLlXS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Average Price of Stay"
      ],
      "metadata": {
        "id": "UhKQL4vkmAJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum=0\n",
        "i=0\n",
        "while i<len(staysdf):\n",
        "  sum=sum+staysdf['Price'][i]\n",
        "  i=i+1\n",
        "avg=sum/len(staysdf)\n",
        "print(avg)"
      ],
      "metadata": {
        "id": "6xngujvbMf1g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}